---
title: "自然语言处理行业一些大实话"
date: 2023-11-21T12:27:28+08:00
draft: false
---

日光之下并无新事之，没想到本小透明也有机会见识行业的一个周期。2017年，当时一波深度学习的浪潮已接近尾声，我加入了北京一家互联网公司的“语义理解”组，开启了NLP行业的打酱油工作。时至今日，我做过2B也做过2C，分析过百万千万用户行为，直面过客户霸霸，标过数据写过需求文档画过原型图，也拖垮过数据库写过内存泄漏，总而言之除了炼丹几乎没有我没有接触过的岗位。（2023了，还有炼丹这个说法吗？）巧合的是，在ChatGPT横空出世两天前，我入职了一家新公司，最近马上入职一周年，回想起来这一年绝大部分时间GPT老师都在头顶阴魂不散，这两天OpenAI的drama又不断发酵，我感到十分有必要写一写这几年的一些见闻，也算是总结一下所谓职业生涯的第一阶段。

# 人工智能表演艺术家

2017年10月，阿里达摩院成立，号称要做基础研究。彼时老板吃饭时说笑：本行业有种人，叫做“人工智能表演艺术家”，比如我，只负责动动嘴皮子，真正干活的是你们。（disclaimer: not that 达摩院 is only 人工智能表演艺术家）当时只当是说笑，但近一年对这句话有了极其深刻的体会。因为在学校里都是跟研究人员打交道，在之前五六年的工作中都是跟研发打交道，以至于创造了一个bubble，默认很多规矩大家都懂不必多说，直到近一年被ChatGPT引发的PR海啸，叠加非科技行业出身的业务需求方的重捶，给我拍死在舒适区。一句话总结下来：

> 商业世界里只有极少数人能理解系统运行的原理，绝大部分人完全依赖于人工智能表演艺术家来想象这个系统。

然而，所谓科技行业一个常见的操作是，前者给后者当乙方，无论是前者做出来的2B产品以后者作为目标客户，还是公司内部后者作为前者的需求方。于是，人工智能表演艺术家就有了存在的意义：作为前者的代表直接服务于后者，也作为中间的缓冲层，调节二者的矛盾。

在“传统机器学习”的范畴里，问题是容易解决的，因为所谓模型大体都是数学公式，可解释性是确定的，无非就是如何讲的更通俗易懂，努努力是可以掰扯清楚的。后来有了深度学习，可解释性变差了，麻烦也大部分都转移到了数据规则的制定，但“大力出奇迹”具有普适性，复杂度倒也可以接受。直到所谓生成式人工智能的出现，特别是GPT3.5披着ChatGPT的皮进入寻常百姓家之后，突然涌现（pun intended）了大批不合格的人工智能表演艺术家，靠一些玩具式的demo“骗”到了绝大多数不理解系统的非AI领域从业者，甚至搞出AI威胁论，这就扯淡了。

# 示例演示 vs 概念验证 vs 大规模生产

曾经打酱油一段时间数据工程的酱油，彼时的老板曾教导，数据相关的工作，一个重要的衡量指标是数据量大小，处理1G数据和处理1T数据是完全不同的思路。类似的，“智能”相关的项目，做proof of concept概念验证和上线生产环境是两码事，生产环境有十万数据和有千万数据更是不能相提并论。简单来讲，概念验证阶段验证的都是头部场景，只要方案稍加设计一般都不会有大问题，或者永远可以说，上线之后继续调优。日活几千的时候，每天的日志一个运营人力加加油都能人工处理完，发布可以随时无脑梭哈，做好备份有问题随时回滚就行，只要不是交易系统一般也没啥太大影响。日活千万甚至过亿的时候，任何一个小改动都要盯紧指标，灰度发布A/B测试统统安排上，稍有不慎就得记一个事故。至于示例演示，come on那也就发布会showcase吸引眼球专用罢了，能说明什么问题？

然而，在不合格的人工智能表演艺术家及其拥趸那里，这些区别是不存在的，只要有一个演示就代表一切就绪可以上无脑上生产。劝是劝不动的，要么随他意无脑上，风险自己担，要么还是换个合作方罢。只怕事要干锅还要背，就有苦说不出了。

# 规则 vs 模型

当年深度学习刚兴起的时候，一众创业公司炼丹炼的热火朝天，一看数据只想灵魂拷问：这些玩意儿写个规则分分钟完事准确率还高，何苦？刚入行的年轻人，面对眼花缭乱的新模型，个个都想试，试完都觉得自己可以改变世界。只可惜在老司机的淫威之下，没办法被按头要求写规则，写很多很多的规则。直到年轻人后来也成了老司机，终于明白，模型算什么东西，还是规则最香。冷启动的时候，接到新业务需求的时候，没有历史数据，训练数据从何谈起？上线之后出问题了，有足够的时间可以等模型重新训练好吗，会不会为了修一个bug写出另外十个bug？被业务方拷问，为什么我同样的输入得到了不同的输出，又或者为什么我同样的输入得到了同样的输出，怎么回答？不是有廿年经验的老司机哪能想到这些事。

到了生成式的年代，问题更多了。怎么确保LLM只生成某个垂直领域的答案？怎么确保答案的一致性？没有被灵魂拷问过的算法研究员不是好正则表达式工程师。

# 模型 vs 工程 vs 产品

机器学习领域一个经典的数字是，在一个机器学习项目中，模型本身的工作量占比仅为30%。不过要我说，一个上点规模的项目，实际占比可能10%不到。算法侧，更多的时间花在数据预处理和模型评测，再加上效果回收和数据迭代。但更重要的，是围绕着算法进行的各种工程投入，包括不限于所谓模型运维，以及软件工程方面的各种基础服务。算法有问题，只是效果问题，但工程一旦出问题，是生死问题。一个典型的场景是，一个产品接入了多种算法服务，那么流量如何路由，服务之间如何调度，服务故障时如何降级，服务稳定性数据一致性如何保障，等等，都不是单单几个模型可以解决的问题。

同样的，到了生成式的年代，还多出来一些特有的问题。是用RAG还是微调，是调三方API还是自己部署，是用通用大模型，还是专有小模型，数据如何存储，性能问题怎么办，流式输出怎么重新设计产品界面，是基于已有功能做优化，还是干脆推倒重来，数据协议怎么更新，数据脱敏怎么做，提示词怎么做版本管理，效果怎么评测，等等。这个列表能无限延展下去，随便哪个问题都不是随随便便有答案。老板一时兴起要搞GPT，哪管做起来纯纯火葬场。

# All in All

提到很多曾经，主要还是想表达一个“日光之下并无新事”。多少大模型项目搞来搞去，兜兜转转还是回到经典系统设计上。科技的发展是很快的，自然语言处理这个领域说是日新月异已经算是低估，但PR之外，这些新科技到底能解决什么问题，值得多大程度投入，才是普通从业者最该思考的。

以上。